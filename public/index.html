<!doctype html>
<html lang="en">

<head>
    <title>The Dual-Route Model of Induction</title>
    <meta charset="utf-8"> 
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="description"
        content="Do LLMs copy meaningful text by rote or by understanding meaning? Webpage for The Dual-Route Model of Induction (Feucht et al., 2025)" />
    <meta property="og:title" content="The Dual-Route Model of Induction" />
    <meta property="og:url" content="https://dualroute.baulab.info/" />
    <meta property="og:image" content="https://dualroute.baulab.info/images/figure1_website.png" />
    <meta property="og:description" content="
    ">
    <meta property="og:type" content="website" />
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="The Dual-Route Model of Induction" />
    <meta name="twitter:description"
        content="Do LLMs copy meaningful text by rote or by understanding meaning? Webpage for The Dual-Route Model of Induction (Feucht et al., 2025)." />
    <meta name="twitter:image" content="https://dualroute.baulab.info/images/figure1_website.png" />
    <link rel="icon" href="favicon.ico?v=2" type="image/x-icon"/>
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/imagfes/favicon/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Math&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
    <link href="style.css" rel="stylesheet">

    <style>
        .relatedthumb {
            float: left;
            width: 200px;
            margin: 3px 10px 7px 0;
        }

        .relatedblock {
            clear: both;
            display: inline-block;
        }

        .bold-sc {
            font-variant: small-caps;
            font-weight: bold;
        }

        .cite,
        .citegroup {
            margin-bottom: 8px;
        }

        :target {
            background-color: yellow;
        }

        .comparison-box {
            border: 2px solid cornflowerblue;
            border-radius: 5px;
            background-color: #e6f0ff; /* light cornflower blue */
            margin: 20px auto;
            max-width: 800px;
            overflow: hidden;
        }
        .box-title {
            background-color: cornflowerblue;
            color: white;
            padding: 10px 15px;
            font-weight: bold;
            font-size: 1.1em;
        }
        .content {
            padding: 15px;
            font-size: 0.9em;
        }
        .divider {
            border-top: 1px solid cornflowerblue;
            margin: 0;
        }
        .original, .ablated {
            margin-bottom: 15px;
        }
        .text {
            margin-top: 5px;
            line-height: 1.5;
        }
        .bold {
            font-weight: bold;
        }
        .underline {
            text-decoration: underline;
            text-decoration-thickness: 2px;
            text-decoration-color: #3366cc;
        }
        .code-container {
            display: flex;
            flex-direction: column;
        }
        @media (min-width: 768px) {
            .code-container {
                flex-direction: row;
            }
        }
        .code-section {
            flex: 1;
            padding: 15px;
        }
        .divider-vertical {
            width: 1px;
            background-color: cornflowerblue;
        }
        .divider-horizontal {
            height: 1px;
            background-color: cornflowerblue;
        }
        pre {
            background-color: #f5f5f5;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
            margin: 0;
            font-family: monospace;
            white-space: pre-wrap;
        }
    </style>
</head>

<body class="nd-docs">
    <div class="nd-pageheader">
        <div class="container">
            <h1 class="lead">
                <nobr class="widenobr">The Dual-Route Model of Induction
                </nobr>
            </h1>
            <address>
                <nobr><a href="https://sfeucht.github.io/" target="_blank">Sheridan Feucht</a>,</nobr>
                <nobr><a href="https://ericwtodd.github.io/" target="_blank">Eric Todd</a>,</nobr>
                <nobr><a href="https://www.byronwallace.com/" target="_blank">Byron C. Wallace</a>,</nobr>
                <nobr><a href="https://baulab.info/" target="_blank">David Bau</a></nobr><br>
                <nobr><a href="https://khoury.northeastern.edu/" target="_blank">Northeastern University</a></nobr>
            </address>
        </div>
    </div><!-- end nd-pageheader -->

    <div class="container">
        <div class="row justify-content-center" style="margin-bottom: 20px">
        </div>
        <div class="row justify-content-center text-center">

            <p>
                <a href="https://arxiv.org/abs/2504.03022" class="d-inline-block p-3 align-top" target="_blank">
                    <img height="100" width="78" src="images/paper-thumb.png" style="border:1px solid; margin: 0 38px;"
                        alt="ArXiv Preprint thumbnail" data-nothumb="">
                    <br>ArXiv<br>Preprint</a>
                <a href="https://github.com/sfeucht/dual-route-induction/" class="d-inline-block p-3 align-top" target="_blank">
                    <img height="100" width="78" src="images/code-thumb.png" style="border:1px solid; margin: 0 38px;"
                        alt="Github code thumbnail" data-nothumb="">
                    <br>GitHub<br>Source Code<br>
                </a>
            </p>
            
            <!-- <div class="card" style="max-width: 1020px;">
                <div class="card-block">
                <h3>How Do LLMs Copy Meaningful Text?</h3>
                <p>
                    <figure class="center_image">
                        <img src="images/dualroute-web-explain.png" class="bigfig">
                    </figure>

                    Imagine you are asked to write down the piece of text shown above on a new piece of paper. There are two ways you might do it: you could either copy every individual letter (the bottom arrows), or you could read the text and understand its meaning, and then write it out again (the top arrows). You might need to do both in order to copy the phrase quickly and accurately. 

                    <br><br>
                    LLMs often have to do a similar task of copying text that previously occurred in their context windows. We find that 
                    they actually develop two parallel mechanisms that allow them to complete this task, analogous to the two routes a human could take to copy a sequence of words. While previous work discovered <i>induction heads,</i> a mechanism in LLMs that allows them to copy exact tokens (the smallest units of text that an LLM sees), we describe a new type of head that LLMs use to copy word meanings, <i>concept induction heads.</i> We go on to show that concept induction heads are actually quite important for other tasks as well, like translating words between two different languages. 
                </p>
                </div>
            </div> -->

            <div class="card" style="max-width: 1020px;">
                <div class="card-block">
                <h3>There are two ways to copy text...</h3>
                <p>
                    Imagine you are asked to copy the nonsense text below onto a new piece of paper. You would have to copy bit-by-bit, slowly transferring one character over at a time. <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">Olsson et al. (2022)</a> previously showed that LLMs do exactly that, by using <i>induction heads</i> to copy text—circuits responsible for copying one token at a time. 

                    <figure class="center_image">
                        <img src="images/dualroute-web-scramble.png" class="bigfig">
                    </figure>

                    But now, imagine that the text you are copying is meaningful ("the false azure in the windowpane"). Here, there are two ways of copying: you could transfer every individual letter like before, or you could leverage your familiarity with each word. Since you already know how to write "windowpane," you don't need to individually copy <tt>w</tt>, <tt>i</tt>, <tt>n</tt>, ... <tt>a</tt>, <tt>n</tt>, <tt>e</tt>. You can just write <i>windowpane</i>.

                    <figure class="center_image">
                        <img src="images/dualroute-web-sensical.png" class="bigfig">
                    </figure>
                    
                    Can LLMs also copy on this semantic level? In this work, we find two types of induction heads: <i>token</i> induction heads, which copy bit-by-bit, and <i>concept</i> induction heads, which copy word meanings instead of individual tokens. Concept induction heads work together with token induction heads to copy meaningful text. We call this synergy the "dual-route model of induction."
                </p>
                </div><!--card-block-->
                </div><!--card-->

        </div><!--row-->

        <div class="row">
            <div class="col">
                <h2>Inspiration: How do Humans Read?</h2>
                Psychologists have developed a <i>dual-route model</i> of reading, which describes two ways that humans can read text (see <a href="https://psychologyoflanguage.pressbooks.tru.ca/chapter/reading-models/#chapter-542-section-4">this textbook section</a> and <a href="https://en.wikipedia.org/wiki/Dual-route_hypothesis_to_reading_aloud">Wikipedia</a>). If readers are looking at a word they already know, they can read it via a lexical pathway that processes whole words at a time, as if they are looking up those words in a dictionary. On the other hand, if readers come across a word they do not know, they must use the <i>sub-lexical</i> route, which decodes individual graphemes into phonemes based on the rules of that language. 

                <figure class="center_image">
                    <img src="images/ramoo.png" class="medfig">
                    <figcaption>Image depicting the dual-route model of reading aloud. Given printed text, a reader can convert from graphemes into phonemes to create speech, or they can map printed words to their semantic meanings and retrieve the pronunciations of those word meanings. (Credit: Ramoo, D. (2021). Psychology of Language. United States: BCcampus, BC Open Textbook Project.)</figcaption>
                </figure>

                <br>
                The existence of a condition called <i>deep dyslexia</i> provides support for this model. After an accident or stroke, people with deep dyslexia can still read and understand word meanings, but often make semantic errors when reading words aloud. For example, someone with deep dyslexia might read the word CANARY as "parrot", or BUCKET as "pail." The first documented case of deep dyslexia came from <a href="literature/marshall_newcombe_1966.pdf">Marshall and Newcombe (1966)</a>, and was later complemented by the discovery of the opposite condition, <i>surface dyslexia,</i> an inability to read without first "sounding out" words (<a href="https://link.springer.com/article/10.1007/BF01067101">Marshall and Newcombe, 1973</a>). 
                

                <br>
                <h2>Our Work: Dual-Route Induction</h2>
                Inspired by this understanding of human reading, we posit a dual-route model of induction. LLMs can either copy text using token-level induction heads  (<a href="https://transformer-circuits.pub/2021/framework/index.html">Elhage et al., 2021</a>; <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">Olsson et al., 2022</a>), or using concept-level induction heads, which copy meaningful representations of entire words. In this paper, we identify concept induction heads in four open-source models, and show that they handle word meanings, which also makes them useful for tasks like translating a word between two languages. 

                <figure class="center_image">
                    <img src="images/figure1_website.png" class="bigfig">
                    <figcaption>Our dual-route model of induction. LLMs develop token induction heads, which are used for verbatim copying, and concept induction heads, important for translation and "fuzzy" copying tasks. These two routes work in parallel to copy meaningful text.</figcaption>
                </figure>

                <h2>Ablating Concept and Token Heads</h2> 
                After identifying token and concept induction heads via causal intervention (see Section 2 of our paper), we test these heads on a new in-context task that requires models to copy word meanings. For example, we give an LLM a list of ten words in French (1. neige, 2. pomme, ... 9. froid, 10. mort) and prompt the model to output the translation of the last word in English (... 9. cold, 10. ___). We also set up tasks where the model has to copy exactly from English -> English. 
                

                <figure class="center_image">
                    <img src="images/ablations.png" class="bigfig">
                    <figcaption>Ablating token induction heads for Llama-2-7b destroys performance for nonsense copying (dark blue), whereas ablating concept induction heads destroys performance for semantic tasks (red). </figcaption>
                </figure>

                You can see the difference between these two sets of heads when you compare the red and dark blue lines. When token induction heads are ablated, we see that performance goes down much faster for "nonsense copying" (<tt>exSh</tt> -> <tt>exSh</tt>) than for other, meaning-based tasks. This is because models can still use concept induction heads for tasks that require copying word meaning. On the other hand, when concept induction heads are ablated, accuracy for translation, synonyms, and antonyms drops off quickly, while token-based tasks remain intact. 

                <br>
                We find that ablating either set of heads has little impact on Llama-2-7b's ability to copy English words, which makes sense: as our intro example demonstrates, you can copy <tt>windowpane</tt> -> <tt>windowpane</tt> whether or not you understand the meaning of that word. Because either mechanism can be used to do this task, we think of these two types of heads as working in parallel. 

                <h2>Ablating Token Induction Heads Causes Paraphrasing</h2>
                When token induction heads are ablated, we find that LLMs start to paraphrase where they would have otherwise done exact copying. We can think of this as "giving the model deep dyslexia"—it is still able to understand semantics, but is no longer able to access exact token information. Much of this rephrasing seems to be on a phrase level, although we do see specific words being replaced with synonyms (e.g., <tt>cases</tt> is replaced by <tt>times</tt>). Section 4.2 and Appendix D.4 show examples of this, and you can also download a notebook to generate paraphrases yourself on <a href="https://github.com/sfeucht/dual-route-induction/blob/main/scripts/qualitative.ipynb">GitHub</a>. 

                <div class="comparison-box">
                    <div class="box-title">(Llama-2-7b) Original Model vs. Top-32 Token Induction Heads Ablated</div>
                    
                    <div class="content">
                        <div class="original">
                            <div class="text">
                                I have reread, not without pleasure, my comments to his lines, and in many cases have caught myself borrowing a kind of opalescent light from my poet's fiery orb.
                            </div>
                            <div class="text bold">
                                I have reread, not without pleasure, my comments to his lines, and in many cases have caught myself borrowing a kind of opalescent light from my poet's fiery orb.
                            </div>
                        </div>
                        
                        <hr class="divider">
                        
                        <div class="ablated">
                            <div class="text">...</div>
                            <div class="text bold">
                                I have reread my comments <span class="underline">on</span> his lines, and I have caught myself many <span class="underline">times</span> borrowing from <span class="underline">his</span> fiery orb a kind of opalescent light.
                            </div>
                        </div>
                    </div>
                </div>

                <body>
                    <div class="comparison-box">
                        <div class="box-title">(Llama-3-8b) Original Model vs. Top-32 Token Induction Heads Ablated</div>
                        
                        <div class="code-container">
                            <!-- Original Model Section -->
                            <div class="code-section">
                                <pre>foo = []
for i in range(len(bar)):
    if i % 2 == 0:
        foo.append(bar[i])
foo = <span class="bold">[] </span>
<span class="bold">for i in range(len(bar)):</span>
    <span class="bold">if i % 2 == 0:</span>
        <span class="bold">foo.append(bar[i]) </span></pre>
                            </div>
                            
                            <!-- Divider for desktop -->
                            <div class="divider-vertical"></div>
                            
                            <!-- Divider for mobile -->
                            <div class="divider-horizontal"></div>
                            
                            <!-- Ablated Model Section -->
                            <div class="code-section">
                                <pre>foo = []
for i in range(len(bar)):
    if i % 2 == 0:
        foo.append(bar[i])
foo = <span class="bold">[bar[i] for i in range( </span>
<span class="bold">len(bar)) if i % 2 == 0]</span></pre>
                            </div>
                        </div>
                    </div>


                <h2>Concept Induction Heads Output Meaning Representations</h2>
                Our experiments show that concept induction heads are important for translation. Building on results from <a href="https://arxiv.org/abs/2411.08745">Dumas et al. (2025)</a> showing that LLMs represent word meanings separate from language, we replicate their experiment in a more surgical way using these newly-found heads. 

                <br><br>
                <figure class="center_image">
                    <img src="images/language-patching.png" class="bigfig">
                    <figcaption>Patching the outputs of concept induction heads from the first prompt causes the model to output "child" in Chinese.</figcaption>
                </figure>
          
                We use the same prompt setup as Dumas et al. (2025) to show that concept induction heads output representations of word meaning that can be expressed in multiple languages. 
                For example, if we take the outputs of concept induction heads when an LLM is translating "niño" ("child") from Spanish to Italian and substitute them into a context where the model is translating from Japanese to Chinese, we can get the model to output "child" in Chinese, "孩子". This suggests that these heads were carrying the meaning of the word "child," but not in any particular language. In other words, concept induction heads are important for translation because they specifically copy <i>semantic</i> information. 

                <h2 id="related-work">Related Work</h2>
                
                <p>Our work builds upon insights from other papers:</p>

                <p class="citation"><a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html"><img src="images/olsson2022.png" alt="Screenshot of Olsson et al. (2022)"> Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, ... Chris Olah. In-Context Learning and Induction Heads. 2022.</a><br>
                    <b>Notes:</b> Based on the initial discovery of induction heads in <a href="https://transformer-circuits.pub/2021/framework/index.html">Elhage et al. (2022)</a>, the authors investigate the connection between in-context learning and induction heads. They find that ICL capabilities are closely related to the development of induction heads. 
                    </p>
                
                <p class="citation"><a href="https://arxiv.org/abs/2411.08745"><img src="images/dumasetal2025.png" alt="Figure 1 from Dumas et al. (2025)">Cl&#233;ment Dumas, Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West. Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers. 2025.</a><br>
                <b>Notes:</b> We build off the work of Dumas et al. (2025) in the second half of this paper. They show that the average of a representation for the same word in multiple languages (e.g., "buch", "libro", "book") can be patched into a new context and decoded in an entirely different language (e.g. 书). We repeat their experiments, except instead of patching averaged hidden states, we patch the outputs of concept induction heads. We see the same effect, suggesting that these heads are responsible for transporting language-agnostic word representations. 
                </p>            

                <p class="citation"><a href="https://footprints.baulab.info"><img src="images/probe-cf.png" alt="Figure from Feucht et al. (2024)">Sheridan Feucht, David Atkinson, Byron Wallace, David Bau. Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs. 2024.</a><br>
                <b>Notes:</b> Our own prior work showed that the last tokens of multi-token words/entities strangely "erase" or lose previous-token information in early layers. We suspected that this is due to the process of <i>detokenization</i>, or conversion from a model's literal token vocabulary to its implicit internal vocabulary (also described by <a href="https://arxiv.org/abs/2410.05864">Kaplan et al. (2024)</a>). Concept induction heads seem to operate over these same implicit vocabulary units. 
                </p>                
                

	
                <h2>How to cite</h2>

                <p>This work is currently under review. It can be cited as follows:
                </p>

                <div class="card">
                    <h3 class="card-header">bibliography</h3>
                    <div class="card-block"> 
                        <p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
                            Sheridan Feucht, Eric Todd, Byron Wallace, and David Bau. "<i>The Dual-Route Model of Induction.</i>" Preprint, arXiv:2504.03022 (2025).</nobr> 
                        </p>
                    </div>
                    <h3 class="card-header">bibtex</h3>
                    <div class="card-block">
                        <pre class="card-text clickselect"
                        >@article{feucht2025dualroute,
    title={The Dual-Route Model of Induction}, 
    author={Sheridan Feucht and Eric Todd and Byron Wallace and David Bau},
    year={2025},
    eprint={2504.03022},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2504.03022}, 
}</pre>
                    </div>
                </div>

            </div> <!--col -->    
        </div> <!--row -->
    </div> <!-- container -->

    

    <footer class="nd-pagefooter">
        <div class="row">
            <div class="col-6 col-md text-center">
                <a href="https://baulab.info/">About the Bau Lab</a>
            </div>
        </div>
    </footer>

</body>

</html>

